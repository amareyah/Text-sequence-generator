{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sample_to_hot_vector_and_target_indexes(sample,dictionary,dic_length):\n",
    "    #here x[0] is all zeros row, it is used as x0=0 as initial input to sequence generation\n",
    "    x = torch.zeros(len(sample)+1,dic_length)\n",
    "    y = torch.empty((len(sample)),dtype=torch.long)\n",
    "    \n",
    "    for j,ch in enumerate(sample):\n",
    "        k = chr_to_idx[ch]\n",
    "        x[j+1,k]=1.0\n",
    "        y[j] = k\n",
    "    return x[:-1], y\n",
    "\n",
    "def encode_samples_to_hot_tensors(samples_list,chr_to_idx_dict):\n",
    "    \n",
    "    dic_length = len(chr_to_idx_dict)\n",
    "    x_train_list = []\n",
    "    \n",
    "    for i, txt in enumerate(samples_list):\n",
    "        x,y = encode_sample_to_hot_vector_and_target_indexes(txt,chr_to_idx_dict,dic_length)\n",
    "        x_train_list.append((x,y))\n",
    "\n",
    "    #x_train_list.sort(key=lambda val: val[0].shape[0],reverse=True)\n",
    "    \n",
    "    return x_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(samples_list,batch_size):\n",
    "    total_samples_num = len(samples_list)    \n",
    "    #total_samples_num = 150\n",
    "\n",
    "    batch_number = int(total_samples_num/batch_size)+int(total_samples_num%batch_size>0)\n",
    "    \n",
    "    rand_indexes = torch.randperm(total_samples_num)\n",
    "    \n",
    "    for i in range(batch_number):\n",
    "        rand_indexes_for_batch = rand_indexes[batch_size*i:batch_size*(i+1)]\n",
    "        batch_samples = [samples_list[j] for j in rand_indexes_for_batch]\n",
    "        batch_samples.sort(key=lambda s: s[0].shape[0],reverse=True)\n",
    "        \n",
    "        yield batch_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_preprocess(batch):\n",
    "    x_list = [sample[0] for sample in batch]\n",
    "    y_list = [sample[1] for sample in batch]\n",
    "    \n",
    "    x_train_batch = torch.nn.utils.rnn.pack_sequence(x_list)\n",
    "    y_target_batch = torch.nn.utils.rnn.pack_sequence(y_list)\n",
    "    \n",
    "    return x_train_batch, y_target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_module(nn.Module):\n",
    "    def __init__(self,hidd_size,num_layers,is_bidirect, dictionary):\n",
    "        super().__init__()\n",
    "        # number of lstm stacked layers\n",
    "        self.num_layers = num_layers \n",
    "        self.input_size = len(dictionary)\n",
    "        self.hidden_size = hidd_size\n",
    "        \n",
    "        # number of directions in lstm\n",
    "        self.num_directions = 2 if is_bidirect else 1 \n",
    "        \n",
    "        self.idx_to_chr = dictionary\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size,num_layers=num_layers,bias=True,batch_first=False,bidirectional=is_bidirect)\n",
    "        self.linear = nn.Linear(self.hidden_size*self.num_directions,self.input_size)\n",
    "    \n",
    "    def _forward(self,x): \n",
    "        #x.shape --> (sequence_length,batch,features_size)\n",
    "        #lstm_out.shape --> (sequence_length,batch,hidden_size)\n",
    "        #h_n, c_n shape --> (num_layers * num_directions, batch, hidden_size)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x) \n",
    "        \n",
    "        #y_hat shape --> (sequence_length,batch,output_size=input_size)\n",
    "        y_hat = self.linear(lstm_out.data)\n",
    "        \n",
    "        return y_hat,(h_n, c_n)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self._forward(x)\n",
    "        \n",
    "    def generate_samples(self,samples_number_to_generate, max_sample_length):\n",
    "        #x.shape --> (sequence_length,batch,features_size)\n",
    "        #lstm_out.shape --> (sequence_length,batch,hidden_size)\n",
    "        #h_n, c_n shape --> (num_layers * num_directions, batch, hidden_size)\n",
    "        x = torch.zeros(1,1,self.input_size)\n",
    "        h_t = c_t = torch.zeros((self.num_layers*self.num_directions,1,self.hidden_size))\n",
    "        \n",
    "        #generated samples are appended to this list\n",
    "        generated_samples_list=[] \n",
    "        \n",
    "        #this list is used for constracting one sample\n",
    "        generated_sample = []     \n",
    "        \n",
    "        #this loop is used to generate desired number of samples\n",
    "        for i in range(samples_number_to_generate): \n",
    "            #here we zero out initial input and initial hidden and state variables\n",
    "            x.zero_()\n",
    "            h_t.zero_()\n",
    "            c_t.zero_()\n",
    "    \n",
    "            for t in range(max_sample_length):\n",
    "                #forward propagating previously generated character given as vector x. \n",
    "                #(h_t,c_t) are hidden and memory state from previous iteration\n",
    "                \n",
    "                #lstm_out shape --> (sequence_length,batch,hidden_size)\n",
    "                #h_n, c_n shape --> (num_layers * num_directions, batch, hidden_size)\n",
    "                lstm_out, (h_t, c_t) = self.lstm(x,(h_t,c_t))\n",
    "                \n",
    "                #y_hat is unnormilized output of linear layer which is applied to output of lstm layer\n",
    "                #y_hat shape --> (sequence_length,batch,output_size=input_size)\n",
    "                y_hat = self.linear(lstm_out)\n",
    "                \n",
    "                #these are probabilities of possible characters (this is probability distribution generated by network)\n",
    "                #we need to squeeze y_hat to obtain one dimensional tensor\n",
    "                #p_model length is dictionary length\n",
    "                p_model = torch.nn.functional.softmax(y_hat,dim=2).squeeze()\n",
    "        \n",
    "                #here we sample index of charachter from probability distribution array\n",
    "                generated_char_ind = torch.multinomial(p_model,1).item()\n",
    "                \n",
    "                #find corresponding character in dictionary for sampled index \n",
    "                generated_char = self.idx_to_chr[generated_char_ind]\n",
    "                \n",
    "                #append this generated charachter to sample being generated. (we construct sample one by one character)\n",
    "                generated_sample.append(generated_char)\n",
    "        \n",
    "                #here we generate hot vector for already generated character and will use it as next input to network\n",
    "                x.zero_()\n",
    "                x[0,0,generated_char_ind]=1.\n",
    "                \n",
    "                #if network generates end of line character, we stop generation for this sample and begin for next sample.\n",
    "                if generated_char=='\\n' or generated_char=='.':\n",
    "                    break\n",
    "            #generate sample string and save that sample to samples list\n",
    "            generated_samples_list.append(''.join(generated_sample))\n",
    "        \n",
    "            #prepare for next sample construction\n",
    "            generated_sample.clear()\n",
    "        \n",
    "        return generated_samples_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_training_samples_num =  None\n",
    "batch_size = 8\n",
    "\n",
    "with open('shakespeare.txt') as f:\n",
    "    whole_text = f.read()\n",
    "    alpha = set(whole_text.lower())\n",
    "    del whole_text\n",
    "    idx_to_chr = {i:c for i,c in enumerate(alpha)}\n",
    "    chr_to_idx = {c:i for i,c in enumerate(alpha)}\n",
    "    f.seek(0)\n",
    "    samples = f.readlines()\n",
    "    samples = [l.lower() for i,l in enumerate(samples) \n",
    "               if total_training_samples_num is None or i < total_training_samples_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_size = len(alpha)\n",
    "hidden_size = 64\n",
    "output_size = dictionary_size\n",
    "num_layers = 2\n",
    "directions_num = 1\n",
    "is_bidirectional = directions_num == 2\n",
    "\n",
    "samples_number_to_generate = 20\n",
    "max_sample_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_tensor_list = encode_samples_to_hot_tensors(samples,chr_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = LSTM_module(hidden_size,num_layers,is_bidirectional,idx_to_chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module.load_state_dict(torch.load('shakspear_weights.pt'))\n",
    "#module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(module.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8467, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5661, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2013, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1937, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0486, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1752, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0521, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1914, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9728, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9533, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7936, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8191, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9233, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9057, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8117, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7534, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8884, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7198, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5588, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7010, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8595, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7404, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6867, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5481, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7467, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5773, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4009, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6448, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6416, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4503, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7505, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6025, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5798, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5292, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6229, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5096, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5167, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5501, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7090, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5329, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5709, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4505, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5465, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5868, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4094, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4827, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5127, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6495, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2409, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2996, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1917, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2755, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3741, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5760, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3402, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4408, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2866, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3041, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4354, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4178, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4184, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4536, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3330, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5476, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2204, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4041, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5757, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4220, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2958, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3092, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2307, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2456, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3169, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3440, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3117, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3444, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2250, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1660, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0909, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2254, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2298, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3064, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1664, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3338, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2816, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3659, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1564, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2108, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2439, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2402, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2438, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2125, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2121, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3198, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1940, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2593, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2659, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0971, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0897, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0160, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0200, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0285, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2044, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0226, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1027, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2242, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1913, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2188, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2571, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1112, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2190, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1416, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2855, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0921, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2416, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1822, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0448, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1573, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0911, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2572, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1622, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2731, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1345, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0273, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0821, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1527, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0317, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1141, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0728, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0567, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1878, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1235, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2304, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0284, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0361, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0654, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0327, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0719, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9805, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9815, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0286, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0694, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8422, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9884, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0879, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0427, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0875, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0737, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0806, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1597, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0271, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9999, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0385, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0375, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9726, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1962, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9606, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0156, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7947, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9716, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0066, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1577, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9968, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9678, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9505, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0463, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9592, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9926, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9718, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9912, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9698, grad_fn=<NllLossBackward>)\n",
      "finished.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    batch_gen = batch_generator(samples_tensor_list,batch_size)\n",
    "    \n",
    "    for batch in batch_gen:\n",
    "        x, y = batch_preprocess(batch)\n",
    "\n",
    "        y_hat, (h_n, c_n) = module(x)\n",
    "\n",
    "        loss = criteria(y_hat, y.data)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print('epoch {} | loss {}'.format(epoch,loss.item()))\n",
    "print('finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_module(\n",
       "  (lstm): LSTM(38, 64, num_layers=2)\n",
       "  (linear): Linear(in_features=64, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generated_samples_list=[]\n",
    "generated_sample = []\n",
    "\n",
    "for i in range(samples_number_to_generate):\n",
    "    x = torch.zeros((1,1,dictionary_size))\n",
    "    \n",
    "    for t in range(max_sample_length):\n",
    "        \n",
    "        y_hat, (h_t, c_t)= module(x)\n",
    "        #print('y_hat {}'.format(y_hat[-1:,:,:].shape))\n",
    "        p_model = F.softmax(y_hat[-1,:,:],dim=1).squeeze()\n",
    "        #print('p_model {}'.format(p_model))\n",
    "        generated_char_ind = torch.multinomial(p_model,1).item()\n",
    "        #print('gen char index: {}'.format(generated_char_ind))\n",
    "        \n",
    "        generated_char = idx_to_chr[generated_char_ind]\n",
    "        #print('gen char: {}'.format(generated_char))\n",
    "        generated_sample.append(generated_char)\n",
    "       \n",
    "        if generated_char=='\\n':\n",
    "            break\n",
    "        \n",
    "        x_1 = torch.zeros(1,1,38)\n",
    "        x_1[0,0,generated_char_ind]=1.0\n",
    "        x = torch.cat((x, x_1,))\n",
    "        \n",
    "        #print(x.shape)\n",
    "    \n",
    "    generated_samples_list.append(''.join(generated_sample))\n",
    "    generated_sample.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if farthemver to could near thou arts new see,\\n',\n",
       " \"but 'bay a long herots hand merim prime,\\n\",\n",
       " 'the rights hum pleasure worth a beutter taken,\\n',\n",
       " 'as you thou book filled not feast budlact leed\\n',\n",
       " 'all fair the careles more, least truthonescy:\\n',\n",
       " \"the uuty travient o'ercaik pastazed\\n\",\n",
       " 'sucuuns me of taked but by thy bodeeus amen.\\n',\n",
       " 'but repinct nor ill my lay ornerd:\\n',\n",
       " \"o no lamcess so love, but loscesixy's ricklow'st,\\n\",\n",
       " \"be in a tortuen of dead, hid write's novace.\\n\",\n",
       " '\\n',\n",
       " 'that to enerraised, sich whilgh pride to woack.\\n',\n",
       " 'she in their takes my love and men my tway.\\n',\n",
       " \"and he abon's fuls and toob, no rulle\\n\",\n",
       " 'a tor the travel negl his full of doun:\\n',\n",
       " 'that i that this love, by younds, are should know:\\n',\n",
       " 'but thence have no love with thy gain gain of me!\\n',\n",
       " \"then if all nature's every what skill,\\n\",\n",
       " 'yet love it be sile, basquaity, that again,\\n',\n",
       " 'and ne wo my placest shall as it gid des,\\n']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_samples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['look an yousing on this unkindnexs compit.',\n",
       " 'but thou art your love)t but with pour loncess sibbl,\\n',\n",
       " 'and suplitie and ever write dispain,\\n',\n",
       " '\\n',\n",
       " 'that dighs thee that so grown larcefol to come:\\n',\n",
       " 'yet look uninions on a keep seir,\\n',\n",
       " '\\n',\n",
       " 'it freth me to sputein, my lies on his,\\n',\n",
       " \"with to creation shall take and dreful's slate,  \\n\",\n",
       " 'in your as firs to the blind so love hight,\\n',\n",
       " \"and other poter, mans must in grown's truth.\",\n",
       " 'when other in grown by, my paines born to-grease.',\n",
       " '  \\n',\n",
       " 'sto how faults with live then musion upon cloke;\\n',\n",
       " 'for that when i may by whisers alter staind,\\n',\n",
       " 'but actient what chide the ceasure beed.',\n",
       " '\\n',\n",
       " 'and sto to him infantcheres stilowed all-owe.',\n",
       " 'the curid cannot be devildedance ote.',\n",
       " 'to witness which others pilture being:\\n']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.generate_samples(20,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(module.state_dict(),'shakspear_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
